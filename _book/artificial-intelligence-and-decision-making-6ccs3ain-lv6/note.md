## 介绍

人工智能主要从两个方面描述：“复刻**人类行为**”和“**理性**”。而大家对”智能“的主题也有两种看法：”智能“是**内部思维推理**，还是**外在行为**的表现。这两个维度会诞生四种不同的人工智能发展方向。

1. 类人行为：比如典型的图灵测试就是测试这类人工智能的，为了“骗过人类”。这类人工智能需要具备以下能力：

   - 自然语言处理：能听和说人类的语言。
   - 知识表示：能存储它接受的知识。
   - 自动推理：回答问题得出结论。
   - 机器学习：适应新环境，推断模式。

   以及可选的计算机视觉和机器人学（不同的输入输出方式吧）。

2. 类人思考：认知科学致力于研究人工智能的计算机模型和心理学。我们可以通过内省（反思自己思考的过程），心理实验（观察受试者的行为）和大脑成像等方式了解人类思维，并让程序模拟这些理论。

3. 理性思考：主要是通过逻辑推理（根据已知的内容推出结论，如：苏格拉底是人，人都是凡人，则苏格拉底是凡人）和概率（弥补不确定的条件），建立理性思维模型。

4. 理性行为：为取得最佳的（确定的或者期望的）结果而采取行动。

理性行为看起来优于类人行为，因为人类的思维模式可能会有很多无法达到的最优解（也就是：**可计算性**和**易处理性**的平衡）。但是完美理性计算代价太高了，环境因素过于复杂。所以后面会讲到有限理性，适当地采取一些行动。

AI：可以进行“思考”，做出决策，给其他软硬件分配任务。

> 做决策并不是 if else 那么简单，并不能涵盖大多数情况。23年我参加ST峰会的时候第一次开始了解AI，当时工作人员介绍他们的工厂电机可以通过深度学习判断一些异常状况（比如设备未水平，或者有异物卡住电机等）来停止电机。我当时就问，我说这为啥要用深度学习呢，不用不也能解决，他和我说状态机并不总是能准确判断所有情况的，利用深度学习总结一些已有模式，决策才会更加准确快速。23年ST的峰会主题之一就是AI的边缘侧应用。

Simple Agent： 给每种 percept 认知指向一个 action。比如，0是周一，1是周二，2是周三……检测到地面脏就开启吸尘，否则拖地……

![image-20240930225951674](https://raw.githubusercontent.com/Jingqing3948/FigureBed/main/mdImages/202409302259773.png)

弊端非常明显，首先代码量很大，情况太多的话速度也会变慢，比如GTA5里有19.8亿次的if。而且我们并不能准确判断出所有情况（地面怎样算脏？90%的部分被遮挡就算脏吗？边缘的90%和中部的90%情况如何清扫？）

所以对于所有可能的情况都准确已知的情况下，simple agent才更好。但是我们的环境中变量，影响因素太多了，大多数时候没有这么简单的情况。

Utility-based agents：穷举出当前情况的所有actions，以及其效用，并递归推导下一步。比如一枚象棋，可以先往哪些方向走，到达这些方向后又可以继续往哪些方向走……我们会发现有的方向走不了因为被其他棋子挡住，有的方向不能走因为可能走到对方棋子攻击范围内了，这些步骤的效用都不好都可以舍弃。

我们还可以根据这些数据计算出期望效用值。

但是效用代理的缺点也很明显，一方面消耗大量资源时间（穷举），另一方面很难看得长远，比如国际象棋棋局，这种代理方式很可能只按照每一步的最佳走法走，长远目光不行。

## LLM

通过构建单词短语之间的关联而建立。根据上文猜测下文应该说的内容，GPT就是非常典型的例子。

缺点在于：

1. 数据全部来源于训练日期前的数据。
2. 训练底层不透明（可能意思是我们很难知道模型被训练成什么样了？）
3. 可能会幻想，自己编造数据。
4. 如果数据来源不准确，不全面，有偏见等，也会影响生成的结果。所以需要很多评估，比如是否有偏见，数据准确度，语调等。

## 概率

这一段基本和机器学习是一样的内容，概率，条件概率，独立，贝叶斯公式等。

马尔科夫链：每个节点都条件独立于其他结点。**一个结点的马尔科夫链是他的父节点，他的子节点，和他的子节点的其他父节点**。

我们可以先用变量描述要解决的问题，然后将其转化为相互条件概率链接的马尔科夫链解决问题。

### Inference by enumeration 枚举推理法

列出所有条件概率。很明显这种方法能涵盖所有情况但是效率低。

![image-20241009144650015](https://raw.githubusercontent.com/Jingqing3948/FigureBed/main/mdImages/202410091446081.png)

### Prior sampling 先验抽样

> 1）先验——根据若干年的统计（经验）或者气候（常识），某地方下雨的概率；
>
> 2）似然——下雨（果）的时候有乌云（因/证据/观察的数据）的概率，即已经有了果，对证据发生的可能性描述；
>
> 3）后验——根据天上有乌云（原因或者证据/观察数据），下雨（结果）的概率；
>
> 后验 ~ 先验*似然 ： 存在下雨的可能（先验），下雨之前会有乌云（似然）~ 通过现在有乌云推断下雨概率（后验）
>
> [机器学习中的先验、后验和似然_先验后验背景-CSDN博客](https://blog.csdn.net/qq_39905917/article/details/83035386)

我们随机抽样一些数字，通过其最终概率规律来预测最终结果，而不是精准地计算出所有条件概率。

因为现实世界中变量概率影响因素太多，这样计算负担过大。

先验采样适用于联合概率。

比如下面这个题：

![image-20241009154642824](https://raw.githubusercontent.com/Jingqing3948/FigureBed/main/mdImages/202410091546895.png)

我们随机生成一个概率序列：0.4 0.2 0.71 0.2

0.4<P(C)，所以C发生。

0.2>=P(S|C)，所以S没发生。

0.71<P(R|C)，所以R发生。

S没发生，R发生的情况下，P(W|S,R)=0.9>0.2，所以W发生。

那么这次采样结果就是：C, not S, R, W。

多采样几次总结出序列 P(c, not s, r, w) 的发生概率，采样越多越精确。

但是先验概率没法算条件概率。

### Rejection Sampling 接受-拒绝定理

比如计算P(X|e)，我们先用先验概率采样所有点，只选择其中落在e中的点进行统计。对于每个点i，让N[X=i]++统计总数，最后正交化数组N[X]统计所有在e范围内的X的概率分布情况。

简单来说就是落在e之外的不用嘛。不过会带来的问题在于，如果e特别小，那么就会浪费很多采样点没用。

### Likelihood weighting

已经观测到结果，条件发生的可能性。

采用最大最有可能发生的概率。

如题：

![image-20241009165638431](https://raw.githubusercontent.com/Jingqing3948/FigureBed/main/mdImages/202410091656513.png)

也就是说，现在观测到下雨 Rain了，那么Cloudy和WetGrass=true的发生概率有多大？

还是按顺序推导。首先设权重w=1.

想满足C=true：让w=0.5

S没要求（not a evidence variable）所以=多少都行，不用改权重值。假设S=false。

R也是同理，不是条件，假设R=true.

想让W=true，w=0.5*0.9=0.45.

所以权重为0.95的时候最可能发生有云且草地湿了后下雨了。

### Gibbs sampling

有点抽象，从一道例题来看吧。

条件概率图如下：

![image-20241009173512060](https://raw.githubusercontent.com/Jingqing3948/FigureBed/main/mdImages/202410091735113.png)

我们想计算： P(Cloudy|Sprinker = true, WetGrass = true)

1. 随机初始化所有变量。evidence variables 的值要固定为题目要求，也就是 Sprinker = true, WetGrass = true。假设初始化得到的是 [Cloudy = true, Rain = false, Spinker = true, WetGrass = true]
2. 先采样 C，其他变量不变。获取 C 的马尔科夫链（S, R），从 P[C | S=true, R=false] 和 P[C=false | S=true, R=false] 中取样。采样完了根据概率分布决定C的值，假设是false。
3. 然后采样 R，其马尔科夫链是（C, S, WG），采样 P[R | C=false, S=true, W=true] 
4. 可能重复上述步骤多次。最后根据采样结果估算这些采样中 P(Cloudy|Sprinker = true, WetGrass = true) 的概率。